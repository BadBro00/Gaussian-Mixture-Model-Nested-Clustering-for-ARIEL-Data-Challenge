{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model Exoplanet Atmospheric Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import delle librerie e file ARIEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import sys\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import taurex.log\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import posterior_utils\n",
    "import ast\n",
    "import numpy as np\n",
    "import warnings\n",
    "import helper\n",
    "import ast\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "importlib.reload(helper) \n",
    "check_parameters_valid = helper.check_parameters_valid\n",
    "sys.path.append(os.path.abspath('./'))\n",
    "importlib.reload(posterior_utils)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.patches import Ellipse\n",
    "from submit_format import *\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import mixture\n",
    "from helper import *\n",
    "from preprocessing import *\n",
    "from submit_format import to_competition_format\n",
    "from posterior_utils import *\n",
    "from spectral_metric import *\n",
    "from FM_utils_final import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.lines import Line2D\n",
    "from submit_format import get_unique_filename\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "taurex.log.disableLogging()\n",
    "np.set_printoptions(suppress=True, linewidth=np.nan, threshold=sys.maxsize)\n",
    "# Filtering dei Warning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"more than 1 Rp value detected in the trace! Using first value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variabili\n",
    "### Utilizziamo lo StandardScaler per trasformare e scalare gli input ottenendo *media unitaria* e *varianza nulla*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 5\n",
    "random_state = 40\n",
    "# random_state = random.randint(1,1000)\n",
    "# print(f'Random State : {random_state}')\n",
    "\n",
    "# Lettura dati dai file \n",
    "aux = np.load('aux.npy')\n",
    "spec_matrix = np.load('spectra.npy')\n",
    "noise = np.load('noise.npy')\n",
    "labels = np.load('label.npy')\n",
    "validTraces = np.load('validTraces.npy')\n",
    "num_spectra = spec_matrix.shape[0]\n",
    "labels_names = ['planet_radius','planet_temp','log_H2O','log_CO2','log_CO','log_CH4','log_NH3']\n",
    "\n",
    "# Setting dei path\n",
    "training_path = './Check_Dataset/TrainingData'\n",
    "training_GT_path = os.path.join(training_path, 'Ground Truth Package')\n",
    "trace_GT = h5py.File(os.path.join(training_GT_path, 'TraceData.hdf5'), \"r\")\n",
    "validTraces = validTraces.astype(np.int64)\n",
    "for X in trace_GT.keys():\n",
    "    tr_GT = trace_GT[X]['tracedata'][()]\n",
    "    weights_GT = trace_GT[X]['weights'][()]\n",
    "    if np.isnan(tr_GT).sum() == 1:\n",
    "        continue\n",
    "    validTraces = np.append(validTraces, int(X[12:]))\n",
    "vt = validTraces\n",
    "test_ind = np.sort(vt - 1)\n",
    "train_ind = np.setdiff1d(np.arange(num_spectra), test_ind)\n",
    "plot_ind = random.sample(range(len(test_ind)), 10)\n",
    "spectra_ind = random.sample(range(len(test_ind)), 10)\n",
    "\n",
    "#-------|Preprocessing dei dati spettrali|--------\n",
    "\n",
    "# Preprocessamento dei test spectra\n",
    "test_spectra = spec_matrix[test_ind, :]\n",
    "test_spectra = augment_data(test_spectra, noise[test_ind, :], repeat=1)\n",
    "test_spectra = test_spectra.reshape(-1, spec_matrix.shape[1])\n",
    "\n",
    "# Preprocessamento dei train spectra\n",
    "train_spectra = spec_matrix[train_ind, :]\n",
    "train_spectra = augment_data(train_spectra, noise[train_ind, :], repeat=n_repeat)\n",
    "train_spectra = train_spectra.reshape(-1, spec_matrix.shape[1])\n",
    "\n",
    "# Dati ausiliari e labels\n",
    "train_aux = aux[train_ind, :]\n",
    "train_aux = np.repeat(train_aux, repeats=n_repeat, axis=0)\n",
    "test_aux = aux[test_ind, :]\n",
    "train_labels = labels[train_ind, :]\n",
    "train_labels = np.repeat(train_labels, repeats=n_repeat, axis=0)\n",
    "test_labels = labels[test_ind, :]\n",
    "\n",
    "# Applichiamo StandardScaler per preservare meglio la distribuzione originale\n",
    "scaler = StandardScaler()\n",
    "train_spectra = scaler.fit_transform(train_spectra)\n",
    "test_spectra = scaler.transform(test_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup per gli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste per salvare tutti gli score\n",
    "posterior_scores = []\n",
    "spectral_scores = []\n",
    "# Inizializziamo la bounds_matrix, ovvero la matrice delle distrubuzioni a priori delle molecole\n",
    "bounds_matrix = default_prior_bounds()\n",
    "beta = 0.8\n",
    "q_list = np.linspace(0.01, 0.99, 10) # Lista di q per il calcolo del quantile\n",
    "opacity_path = \"./XSEC/\"\n",
    "CIA_path = \"./HITRAN\"\n",
    "# Carichiamo i dati dello strumento simulato di ARIEL\n",
    "ariel_wlgrid, ariel_wlwidth, ariel_wngrid, ariel_wnwidth = ariel_resolution()\n",
    "# Inizializziamo il forward model (modello planetario)\n",
    "fm = initialise_forward_model(opacity_path, CIA_path)\n",
    "RJUP = 69911000\n",
    "MJUP = 1.898e27\n",
    "RSOL = 696340000\n",
    "Rs = aux[:, 2] / RSOL\n",
    "Mp = aux[:, 4] / MJUP\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applicazione del Clustering\n",
    "- $K_1$ : numero di cluster di 1o livello\n",
    "- $K_2$ : numero di 'sottocluster' (cluster di 2o livello)\n",
    "- $GMM_i$ : output del Gaussian Mixture Model\n",
    "- $Labels_i$ : labels ottenute dal GMM di ciascun livello\n",
    "> Cerchiamo, in ogni sottocluster (K2), i cluster contenenti un singolo spettro, che sono considerati *outlier*, cioe' anomali (composti da un solo spettro)\n",
    "\n",
    "`Si puo' usare il BIC (o l'AIC) per ottenere i migliori valori di $K_1$ e $K_2$`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (19,15) risulta essere la migliore coppia\n",
    "K1 = 19\n",
    "K2 = 15\n",
    "GMM_i = []\n",
    "Labels_i = []\n",
    "\n",
    "pl_cluster_map = {}\n",
    "final_labels = [None] * len(train_aux)\n",
    "subclusters = 0\n",
    "K1_szs = []\n",
    "K2_szs = []\n",
    "\n",
    "# Primo clustering (1° livello) sui dati ausiliari\n",
    "gmm = mixture.GaussianMixture(n_components=K1, random_state=random_state, max_iter=400).fit(train_aux)\n",
    "labels_1 = gmm.predict(train_aux)\n",
    "for i in range(K1):\n",
    "    spectra_i = np.where(labels_1 == i)[0]\n",
    "    print(\"Spettri nel cluster #\", i, \" -> \", len(spectra_i))\n",
    "    # Secondo clustering (2° livello) sui dati spettrali appartenenti al cluster i\n",
    "    tmp = mixture.GaussianMixture(n_components=K2, random_state=random_state).fit(train_spectra[spectra_i, :])\n",
    "    labels_2 = tmp.predict(train_spectra[spectra_i, :])\n",
    "    GMM_i.append(tmp)\n",
    "    Labels_i.append(labels_2)\n",
    "    K1_szs.append(len(spectra_i))\n",
    "    for j in range(K2):\n",
    "        spectra_j = np.where(labels_2 == j)[0]\n",
    "        if len(spectra_j) == 1:\n",
    "            print(f\"\\t [{i}].{j} sottocluster con singolo spettro [OUTLIER]\")\n",
    "            #spectra_i = np.delete(spectra_i,spectra_j) # Rimozione dell'outlier\n",
    "        K2_szs.append(len(spectra_j))\n",
    "        cluster_name = f\"{i}.{j}\"\n",
    "        subclusters+=1\n",
    "        for id1,id2 in zip(spectra_i, spectra_j):\n",
    "            cluster_level = f'{i}.{id2}'\n",
    "            final_labels[id1] = cluster_level\n",
    "\n",
    "pl_cluster_map = {str(int(pid[0])): label for pid, label in zip(train_aux, final_labels) if label is not None}\n",
    "pl_cluster_map = {f\"train{key}\": value for key, value in pl_cluster_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Istogrammi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "labs = ['1° livello', '2° livello']\n",
    "vals = [K1, K2]\n",
    "'''\n",
    "plt.bar(labs, vals, color=['blue', 'orange'])\n",
    "plt.xlabel('Livello di clustering') \n",
    "plt.ylabel('Dimensioni del cluster')\n",
    "plt.title('Distribuzione delle dimensioni dei cluster')\n",
    "plt.tight_layout()\n",
    "plt.yticks(np.arange(0, max(vals) + 1, 1))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "hist_name1 = get_unique_filename('Clusters_dims','.png','Clusters/')\n",
    "plt.savefig(hist_name1)\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# Bar chart - 1° livello (19 cluster)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(range(len(K1_szs)), K1_szs, color='blue')\n",
    "plt.title('Dimensioni cluster di 1° livello')\n",
    "plt.xlabel('Cluster index (1° livello)')\n",
    "plt.ylabel('Dimensione cluster')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "hist_name2 = get_unique_filename('Clusters_dims_log','.png','Clusters/')\n",
    "plt.savefig(hist_name2)\n",
    "plt.show()\n",
    "\n",
    "# Istogramma - 2° livello (19*15 = 285 sottocluster)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(K2_szs, bins=15, color='orange', alpha=0.7, edgecolor='black')\n",
    "plt.title('Dimensioni sottocluster (2° livello)')\n",
    "plt.xlabel('Dimensione sottocluster')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "hist_name3 = get_unique_filename('Subclusters_dims_log','.png','Clusters/')\n",
    "plt.savefig(hist_name3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo degli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste per salvare tutti gli score\n",
    "posterior_scores = []\n",
    "spectral_scores = []\n",
    "# Inizializziamo la bounds_matrix, ovvero la matrice delle distrubuzioni a priori delle molecole\n",
    "bounds_matrix = default_prior_bounds()\n",
    "beta = 0.8\n",
    "q_list = np.linspace(0.01, 0.99, 10) # Lista di q per il calcolo del quantile\n",
    "opacity_path = \"./XSEC/\"\n",
    "CIA_path = \"./HITRAN\"\n",
    "# Carichiamo i dati dello strumento simulato di ARIEL\n",
    "ariel_wlgrid, ariel_wlwidth, ariel_wngrid, ariel_wnwidth = ariel_resolution()\n",
    "# Inizializziamo il forward model (modello planetario)\n",
    "fm = initialise_forward_model(opacity_path, CIA_path)\n",
    "RJUP = 69911000\n",
    "MJUP = 1.898e27\n",
    "RSOL = 696340000\n",
    "Rs = aux[:, 2] / RSOL\n",
    "Mp = aux[:, 4] / MJUP\n",
    "# Calcoliamo lo score solo su una parte dei sample (fino a 2*spec_max)\n",
    "spec_max = 30\n",
    "n_spec = 0\n",
    "spec_ind = random.sample(range(len(test_ind)),spec_max*2)\n",
    "'''\n",
    "# Liste per salvare i parametri usati e gli score ottenuti\n",
    "k1_vals = []\n",
    "k2_vals = []\n",
    "posterior_scores_k = []\n",
    "spectral_scores_k = []\n",
    "scores_k = []\n",
    "'''\n",
    "pl_inds = []\n",
    "all_w = []\n",
    "all_p = []\n",
    "for X in range(len(test_ind)):\n",
    "\t# Fitting sui dati ausiliari\n",
    "\tidx1 = gmm.predict(test_aux[X, :].reshape(1, -1))[0]\n",
    "\tkm = GMM_i[idx1] \n",
    "\tlabels_2 = Labels_i[idx1]\n",
    "\t# Fitting sui dati spettrali\n",
    "\tidx2 = km.predict(test_spectra[X, :].reshape(1, -1))[0]\n",
    "\tidx_1 = np.where(labels_1 == idx1)[0]\n",
    "\tidx_2 = np.where(labels_2 == idx2)[0]\n",
    "\tcluster_membs = idx_1[labels_2==idx2] # Indici dei membri del cluster\n",
    "\t# Estraiamo i membri del cluster\n",
    "\tlab = train_labels[cluster_membs,:]\n",
    "\tlab = lab.reshape(-1,lab.shape[-1])\n",
    "\tposterior = lab\n",
    "\tall_p.append(posterior)\n",
    "\t# Calcoliamo il peso di ogni membro del cluster\n",
    "\tweights1 = np.ones((posterior.shape[0],1)) / posterior.shape[0] # Pesi statici unitari\n",
    "\tall_w.append(weights1)\n",
    "\tplanet_index = test_ind[X]+1\n",
    "\tpl_inds.append(f'train{planet_index}')\n",
    "\t# Carichiamo i dati del ground truth\n",
    "\ttr_GT = trace_GT[f'Planet_train{planet_index}']['tracedata'][()]\n",
    "\twh_GT = trace_GT[f'Planet_train{planet_index}']['weights'][()]\n",
    "\t# Controllo se ci sono nan -> se ci sono, non calcoliamo lo score\n",
    "\tif np.isnan(tr_GT).sum() >= 1:\n",
    "\t\tprint(\"nan trovato\")\n",
    "\t\texit()\n",
    "\tscore = compute_posterior_loss(posterior, weights1, tr_GT, wh_GT,bounds_matrix)\n",
    "\tposterior_scores.append(score)\n",
    "\tif n_spec<spec_max and X in spec_ind:\n",
    "\t\ttry:\n",
    "\t\t\tproxy_compute_spectrum = setup_dedicated_fm(fm, test_ind[X], Rs, Mp, ariel_wngrid, ariel_wnwidth )\n",
    "\t\t\tsscore = compute_spectral_loss(posterior, weights1, tr_GT, wh_GT, bounds_matrix, proxy_compute_spectrum, q_list)\n",
    "\t\t\tspectral_scores.append(sscore)\n",
    "\t\t\tprint('*****Spectral: ',sscore)\n",
    "\t\t\tprint('*****Posterior: ',score)\n",
    "\t\t\tn_spec+=1\n",
    "\t\texcept RuntimeWarning:\n",
    "\t\t\tcontinue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcolo degli score medi\n",
    "- Posterior Score : 80%\n",
    "- Spectral Score : 20%\n",
    "- Final score = Score finale per la Leaderboard\n",
    "> final_score = 0.8 * posterior_score + 0.2 * spectral_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_posterior_score = np.mean(posterior_scores)\n",
    "print(f'Posterior_Score: {avg_posterior_score}')\n",
    "avg_spectral_score = np.mean(spectral_scores)\n",
    "print(f'Spectral_Score: {avg_spectral_score}')\n",
    "final_score = (1 - beta) * avg_spectral_score + beta * avg_posterior_score # beta = 0.8 -> (1-beta) = 0.2\n",
    "print(f\"final score: {final_score:.4f}\")    \n",
    "'''\n",
    "# Salvataggio risultati\n",
    "k1_vals.append(K1)\n",
    "k2_vals.append(K2)\n",
    "posterior_scores_k.append(avg_posterior_score)\n",
    "spectral_scores_k.append(avg_spectral_score)\n",
    "scores_k.append(final_score)\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "    f.write(\"\\n------------------------------\\n\")\n",
    "    f.write(\"K1: {}\\n\".format(k1_vals))\n",
    "    f.write(\"K2: {}\\n\".format(k2_vals))\n",
    "    f.write(\"Posterior scores: {}\\n\".format(posterior_scores_k))\n",
    "    f.write(\"Spectral scores: {}\\n\".format(spectral_scores_k))\n",
    "    f.write(\"Final scores: {}\\n\".format(scores_k))\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting grafico Score/Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "score_plot_ind = 0\n",
    "# Leggi l'intero contenuto del file di testo\n",
    "with open(\"results.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "# Suddividi in blocchi\n",
    "blocks = [block for block in content.split('------------------------------') if block.strip()]\n",
    "# Liste per accumulare i dati di TUTTE le iterazioni\n",
    "k1_values = []\n",
    "k2_values = []\n",
    "posterior_vals = []\n",
    "spectral_vals = []\n",
    "final_vals = []\n",
    "# Funzione per fare il parsing di un valore in modo sicuro\n",
    "def safe_literal_eval(value):\n",
    "    try:\n",
    "        value = value.strip().lower()\n",
    "        if value == \"nan\":\n",
    "            return np.nan\n",
    "        return ast.literal_eval(value)\n",
    "    except (SyntaxError, ValueError):\n",
    "        print(f\"Errore nel parsing: {value}\")\n",
    "        return None\n",
    "# Parsing di tutti i blocchi\n",
    "for block in blocks:\n",
    "    k1, k2 = None, None\n",
    "    posterior = spectral = final = None\n",
    "    lines = [line.strip() for line in block.strip().splitlines() if line.strip()]\n",
    "    for line in lines:\n",
    "        if line.startswith(\"K1:\"):\n",
    "            k1 = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"K2:\"):\n",
    "            k2 = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Posterior\"):\n",
    "            posterior = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Spectral\"):\n",
    "            spectral = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Final\"):\n",
    "            final = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "    # Se tutti i valori sono validi, registra una riga\n",
    "    if all(v is not None for v in [k1, k2, posterior, spectral, final]):\n",
    "        k1_values.append(k1)\n",
    "        k2_values.append(k2)\n",
    "        # Se posterior/spectral/final sono array/list, fai la media\n",
    "        posterior_vals.append(np.mean(posterior) if isinstance(posterior, (list, tuple, np.ndarray)) else posterior)\n",
    "        spectral_vals.append(np.mean(spectral) if isinstance(spectral, (list, tuple, np.ndarray)) else spectral)\n",
    "        final_vals.append(np.mean(final) if isinstance(final, (list, tuple, np.ndarray)) else final)\n",
    "        if len(spectral_vals) < 500: \n",
    "            continue\n",
    "k_pairs = [f\"({k1},{k2})\" for k1, k2 in zip(k1_values, k2_values)]\n",
    "valid_pairs = [i for i,k2v in enumerate(k2_values)if k2v != 1]\n",
    "valid_k1 = [k1_values[i] for i in valid_pairs]\n",
    "valid_k2 = [k2_values[i] for i in valid_pairs]\n",
    "k_pairs = [f\"({k1},{k2})\" for k1, k2 in zip(valid_k1, valid_k2)]\n",
    "# Plot con coppie (K1,K2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_pos = np.arange(len(k_pairs))\n",
    "plt.plot(x_pos, posterior_vals, marker='o', color='red', label='Posterior Score', linestyle='--')\n",
    "plt.plot(x_pos, spectral_vals, marker='x', color='black', label='Spectral Score', linestyle='-.')\n",
    "plt.plot(x_pos, final_vals, marker='*', color='blue', label='Final Score', linestyle=':')\n",
    "plt.xticks(x_pos, k_pairs, rotation=45, ha='right', fontsize=8)\n",
    "plt.xlabel('(K1, K2)', fontweight='bold')\n",
    "plt.ylabel('Scores', fontweight='bold')\n",
    "plt.title('Confronto Scores per Configurazioni (K1,K2)', pad=20)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "# Plot dei punti\n",
    "for i, (p, s, f) in enumerate(zip(posterior_vals, spectral_vals, final_vals)):\n",
    "    plt.annotate(f'{p:.1f}', (x_pos[i], p), textcoords=\"offset points\", xytext=(0,5), ha='center', color='red', fontsize=8)\n",
    "    plt.annotate(f'{s:.1f}', (x_pos[i], s), textcoords=\"offset points\", xytext=(0,5), ha='center', color='black', fontsize=8)\n",
    "    plt.annotate(f'{f:.1f}', (x_pos[i], f), textcoords=\"offset points\", xytext=(0,5), ha='center', color='blue', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plot_fname = get_unique_filename('Grafico','.png','./Cluster_Scores/')\n",
    "plt.savefig(plot_fname)\n",
    "plt.show()\n",
    "\n",
    "# Scrittura su CSV dei risultati\n",
    "#df_results = pd.DataFrame({\n",
    "#    'K1': k1_values,\n",
    "#    'K2': k2_values,\n",
    "#    'PosteriorScore': posterior_vals,\n",
    "#    'SpectralScore': spectral_vals,\n",
    "#    'FinalScore': final_vals\n",
    "#})\n",
    "# Salva su CSsdwdV\n",
    "#df_results.to_csv('results.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function per plot di singole curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_plot_score(k1_prima_curva, k1_seconda_curva, df, score_type='FinalScore'):\n",
    "    \"\"\"\n",
    "    Plotta un singolo score (score_type) per due valori di K1 in funzione di K2.\n",
    "    \n",
    "    Parametri:\n",
    "      - k1_prima_curva: primo valore di K1\n",
    "      - k1_seconda_curva: secondo valore di K1\n",
    "      - df: DataFrame contenente le colonne ['K1','K2','PosteriorScore','SpectralScore','FinalScore']\n",
    "      - score_type: stringa con il nome dello score da plottare ('FinalScore','SpectralScore','PosteriorScore')\n",
    "    \"\"\"\n",
    "    # Filtra e ordina i dati per i due valori di K1\n",
    "    subset1 = df[df['K1'] == k1_prima_curva].sort_values(by='K2')\n",
    "    subset2 = df[df['K1'] == k1_seconda_curva].sort_values(by='K2')\n",
    "    if subset1.empty and subset2.empty:\n",
    "        print(f\"Nessun dato disponibile per K1={k1_prima_curva} o K1={k1_seconda_curva}\")\n",
    "        return\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # Plot per il primo K1\n",
    "    if not subset1.empty:\n",
    "        plt.plot(subset1['K2'], subset1[score_type],marker='o', label=f'K1={k1_prima_curva}', color='red')\n",
    "    # Plot per il secondo K1\n",
    "    if not subset2.empty:\n",
    "        plt.plot(subset2['K2'], subset2[score_type],marker='o', label=f'K1={k1_seconda_curva}', color='blue')\n",
    "    k2_union = sorted(set(subset1['K2']).union(subset2['K2']))\n",
    "    plt.xticks(k2_union)\n",
    "    plt.xlabel('K2')\n",
    "    plt.ylabel(score_type)\n",
    "    plt.title(f'Andamento {score_type} per K1={k1_prima_curva} vs K1={k1_seconda_curva}')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.grid(True)\n",
    "    y_min, y_max = plt.ylim()\n",
    "    margine = (y_max - y_min) * 0.3\n",
    "    plt.ylim(y_min - margine, y_max + margine)\n",
    "    plot_fname = get_unique_filename(f'Plot_{score_type}_{k1_prima_curva}-{k1_seconda_curva}', '.png',directory='./Grafici_Clustering')\n",
    "    plt.savefig(plot_fname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafico andamento clustering\n",
    "### Fissato K1, il grafico indica l'andamento del final_score per il variare di K2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#------------|PLOT FINAL SCORE|------------#\n",
    "df = pd.read_csv('results.csv')\n",
    "# Rinomina delle colonne (se necessario)\n",
    "df.columns = ['K1', 'K2', 'PosteriorScore', 'SpectralScore', 'FinalScore']\n",
    "#-----Rimuovi le parentesi quadre e converti K1 e K2 in interi\n",
    "df['K1'] = df['K1'].str.replace(r'[\\[\\]]', '', regex=True).astype(int)\n",
    "df['K2'] = df['K2'].str.replace(r'[\\[\\]]', '', regex=True).astype(int)\n",
    "#-----Filtraggio cluster a singolo sottocluster\n",
    "df = df[df['K2'] != 1]  # esclude le righe dove K2 è 1\n",
    "# Ordina il dataframe per K1 e K2\n",
    "df = df.sort_values(by=['K1', 'K2'])\n",
    "k1_values = sorted(df['K1'].unique())\n",
    "unique_k2 = sorted(df['K2'].unique())\n",
    "colormap = plt.cm.get_cmap('tab10', len(k1_values)+2)\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, k1 in enumerate(k1_values):\n",
    "    subset = df[df['K1'] == k1].sort_values(by='K2')\n",
    "    plt.plot(subset['K2'], subset['FinalScore'], marker='o', label=f'K1={k1}', color=colormap(i))\n",
    "plt.xticks(unique_k2)\n",
    "plt.xlabel('K2')\n",
    "plt.ylabel('Final Score')\n",
    "plt.title('Andamento final_score')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.subplots_adjust(right=0.7)\n",
    "plt.grid(True)\n",
    "y_min, y_max = plt.ylim()  # prendi i limiti correnti\n",
    "margine = (y_max - y_min) * 0.3  # aggiunge un margine del 30%\n",
    "plt.ylim(y_min - margine, y_max + margine)\n",
    "final_fname = get_unique_filename(f'Grafico_Final_{K1}-{K2}', '.png', directory='./Grafici_Clustering')\n",
    "plt.savefig(final_fname)\n",
    "plt.show()\n",
    "#------------|PLOT SPECTRAL SCORE|------------#\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, k1 in enumerate(k1_values):\n",
    "    subset = df[df['K1'] == k1].sort_values(by='K2')\n",
    "    plt.plot(subset['K2'], subset['SpectralScore'], marker='x', label=f'K1={k1}', color=colormap(i))\n",
    "plt.xticks(unique_k2)\n",
    "plt.xlabel('K2')\n",
    "plt.ylabel('Spectral Score')\n",
    "plt.title('Andamento spectral_score')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.subplots_adjust(right=0.7)\n",
    "plt.grid(True)\n",
    "y_min, y_max = plt.ylim()  # prendi i limiti correnti\n",
    "margine = (y_max - y_min) * 0.3  # aggiunge un margine del 30%\n",
    "plt.ylim(y_min - margine, y_max + margine)\n",
    "spec_fname = get_unique_filename(f'Grafico_Spectral_{K1}-{K2}', '.png', directory='./Grafici_Clustering')\n",
    "plt.savefig(spec_fname)\n",
    "plt.show()\n",
    "#------------|PLOT POSTERIOR SCORE|------------#\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, k1 in enumerate(k1_values):\n",
    "    subset = df[df['K1'] == k1].sort_values(by='K2')\n",
    "    plt.plot(subset['K2'], subset['PosteriorScore'], marker='o', label=f'K1={k1}', color=colormap(i))\n",
    "plt.xticks(unique_k2)\n",
    "plt.xlabel('K2')\n",
    "plt.ylabel('Posterior Score')\n",
    "plt.title('Andamento posterior_score')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.subplots_adjust(right=0.7)\n",
    "plt.grid(True)\n",
    "y_min, y_max = plt.ylim()  # prendi i limiti correnti\n",
    "margine = (y_max - y_min) * 0.3  # aggiunge un margine del 30%\n",
    "plt.ylim(y_min - margine, y_max + margine)\n",
    "base_fname = f'Grafico_Posterior_{K1}-{K2}'\n",
    "post_fname = get_unique_filename(base_name=base_fname, extension='.png', directory='./Grafici_Clustering')\n",
    "plt.savefig(post_fname)\n",
    "plt.show()\n",
    "#-------------------------------\n",
    "# Plotting di sole due curve (K1,K2) per confronto sullo score\n",
    "crea_plot_score(19,3,df,'SpectralScore')\n",
    "crea_plot_score(19,3,df,'PosteriorScore')\n",
    "crea_plot_score(19,3,df,'FinalScore')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting delle distribuzioni\n",
    "### Si utiliza 'corner' per il plot delle distribuzioni bayesiane a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottiamo le distribuzioni dei `plot_ind` spettri\n",
    "for X in plot_ind:\n",
    "\t# Predizione sui dati ausiliari di test (1o livello)\n",
    "\tidx1 = gmm.predict(test_aux[X,:].reshape(1,-1))[0]\n",
    "\tkm = GMM_i[idx1] # Selezione etichette\n",
    "\tlabels_2 = Labels_i[idx1] \n",
    "\t# Predizione sui dati spettrali di test (2o livello)\n",
    "\tidx2 = km.predict(test_spectra[X,:].reshape(1,-1))[0]\n",
    "\tidx_1 = np.where(labels_1 == idx1)[0] # Individuazione indici nel cluster\n",
    "\tidx_2 = np.where(labels_2 == idx2)[0] # Individuazione indici nel cluster\n",
    "\tlab = train_labels[idx_1[idx_2],:] \n",
    "\tmean_lab = np.mean(lab,axis=0) # Media delle predizioni per il plot\n",
    "\tmean_GT = np.average(tr_GT,axis=0,weights=wh_GT) # Valore medio pesato dei dati reali\n",
    "\t# Lettura dati Ground Truth\n",
    "\ttr_GT = trace_GT[f'Planet_train{test_ind[X]+1}']['tracedata'][()]\n",
    "\twh_GT = trace_GT[f'Planet_train{test_ind[X]+1}']['weights'][()]\n",
    "\t# Creazione della figura e plot dei dati reali\n",
    "\tfigure = corner.corner(tr_GT,quiet=True) #,weights=wh_GT\n",
    "\taxes = np.array(figure.axes).reshape((tr_GT.shape[1], tr_GT.shape[1]))\n",
    "\t# Creazione della legenda\n",
    "\tlegend_elements = [\n",
    "        Line2D([0], [0], color='blue', lw=2, label='Distribuzione Reale (tr_GT)'),\n",
    "        Line2D([0], [0], color='red', lw=2, label='Distribuzione Predetta (lab)'),\n",
    "        Line2D([0], [0], color='green', lw=2, label='Valore Reale (test_labels)'),\n",
    "        Line2D([0], [0], color='black', lw=2, label='Media Predetta (mean_lab)')\n",
    "    ]\n",
    "\t# Plot delle distribuzioni (reali)\n",
    "\tfor i in range(tr_GT.shape[1]):\n",
    "\t\tax = axes[i, i]\n",
    "\t\tax.sharex(axes[tr_GT.shape[1]-1,i])\n",
    "\t\tax.axvline(test_labels[X,i], color=\"g\",lw=2)\n",
    "\t\tax.axvline(mean_lab[i], color=\"r\",lw=1.5)\n",
    "\t\tax.axvline(mean_GT[i],color=\"blue\",lw=2)\n",
    "\t\t#ax.axvspan(mean_lab[i] - std_lab[i], mean_lab[i] + std_lab[i], alpha=0.3, color='red')\n",
    "\t\tax.relim()\n",
    "\t\tax.autoscale()\n",
    "\t\tax.set_title(labels_names[i])\n",
    "\tfigure.legend(\n",
    "        handles=legend_elements, \n",
    "        loc='upper right', \n",
    "        bbox_to_anchor=(0.92, 0.92),\n",
    "        frameon=True,\n",
    "        framealpha=0.9\n",
    "    )\n",
    "\tfigure.set_figheight(8.5)\n",
    "\tfigure.set_figwidth(12)\n",
    "\t# Plot delle predizioni\n",
    "\tcorner.corner(lab,fig=figure,quiet=True, color='red')\n",
    "\tfigure.savefig('./GMM_plots/Relevant_Plots/Planet_'+str(test_ind[X]+1)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dei rapporti P/R e P/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Caricamento e preparazione dei dati ---\n",
    "auxT_path = './Check_Dataset/TrainingData/AuxillaryTable.csv'\n",
    "fmParam_path = './Check_Dataset/TrainingData/Ground Truth Package/FM_Parameter_Table.csv'\n",
    "\n",
    "df_aux = pd.read_csv(auxT_path)\n",
    "df_fm = pd.read_csv(fmParam_path)\n",
    "df_merged = pd.merge(df_aux, df_fm, on='planet_ID')\n",
    "df_merged['planet_ID'] = df_merged['planet_ID'].astype(str)\n",
    "\n",
    "# Calcola rapporti (usati eventualmente per altri plot)\n",
    "df_merged['Rapporto_PM'] = df_merged['planet_orbital_period'] / df_merged['planet_mass_kg']\n",
    "df_merged['Rapporto_PR'] = df_merged['planet_orbital_period'] / df_merged['planet_radius']\n",
    "\n",
    "# pl_inds e pl_cluster_map devono essere definiti nel tuo ambiente\n",
    "pl_ind_str = [str(x) for x in pl_inds]\n",
    "df_merged['cluster_label'] = df_merged['planet_ID'].map(pl_cluster_map)\n",
    "\n",
    "# Seleziona solo i pianeti presenti in pl_inds e che hanno un cluster assegnato\n",
    "df_clustered = df_merged[\n",
    "    df_merged['planet_ID'].isin(pl_ind_str) & df_merged['cluster_label'].notna()\n",
    "].copy()\n",
    "\n",
    "df_clustered['cluster_label'] = df_clustered['cluster_label'].astype('category')\n",
    "df_clustered['cluster_label_code'] = df_clustered['cluster_label'].cat.codes\n",
    "\n",
    "# Crea la colonna \"cluster_livello1\" (primo livello, cioè la parte prima del punto)\n",
    "df_clustered['cluster_livello1'] = df_clustered['cluster_label'].apply(\n",
    "    lambda x: x.split('.')[0] if isinstance(x, str) else x\n",
    ").astype('category')\n",
    "\n",
    "# Ordina i cluster di primo livello in ordine crescente\n",
    "categories_lvl1 = sorted(\n",
    "    df_clustered['cluster_livello1'].cat.categories,\n",
    "    key=lambda x: float(x) if x.isdigit() else x\n",
    ")\n",
    "colors_lvl1 = plt.cm.tab10(np.linspace(0, 1, len(categories_lvl1)))\n",
    "\n",
    "# --- Classificazione fisica dei pianeti ---\n",
    "def classify_planet(row):\n",
    "    period = row['planet_orbital_period']\n",
    "    mass = row['planet_mass_kg']\n",
    "    radius = row['planet_radius']\n",
    "    # Soglie esemplificative – adattale in base al dataset\n",
    "    if period < 10 and mass > 1e27:\n",
    "        return 'Hot Jupiter'\n",
    "    elif mass < 5e25:\n",
    "        return 'Super Earth'\n",
    "    elif period > 100 and mass > 1e27:\n",
    "        return 'Cold Jupiter'\n",
    "    else:\n",
    "        return 'Earth-Like'\n",
    "\n",
    "df_clustered['phys_category'] = df_clustered.apply(classify_planet, axis=1)\n",
    "\n",
    "# Crea una mappa di colori per le categorie fisiche\n",
    "categories_phys = df_clustered['phys_category'].unique()\n",
    "colors_phys = plt.cm.Set1(np.linspace(0, 1, len(categories_phys)))\n",
    "phys_color_map = {cat: colors_phys[i] for i, cat in enumerate(categories_phys)}\n",
    "\n",
    "# Parametri per ridurre l'overplotting\n",
    "'''\n",
    "marker_size = 20\n",
    "alpha_val = 0.7\n",
    "jitter_x = 0.05 * df_clustered['planet_orbital_period'].std()\n",
    "jitter_radius = 0.05 * df_clustered['planet_radius'].std()\n",
    "jitter_mass = 0.05 * df_clustered['planet_mass_kg'].std()\n",
    "'''\n",
    "# --- Grafici basati sul primo livello (cluster_level1) ---\n",
    "\n",
    "total_points = 0\n",
    "\n",
    "# Plot Rapporto Periodo-Raggio (1° livello)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, cl in enumerate(categories_lvl1):\n",
    "    mask = df_clustered['cluster_livello1'] == cl\n",
    "    if mask.sum() > 0:\n",
    "        plt.scatter(\n",
    "            df_clustered.loc[mask, 'planet_orbital_period'],\n",
    "            df_clustered.loc[mask, 'planet_radius'],\n",
    "            color=colors_lvl1[i],\n",
    "            alpha=0.9,\n",
    "            edgecolors='black',\n",
    "            label=f'C1: {cl}'\n",
    "        )\n",
    "    total_points += mask.sum()\n",
    "print(f\"Totale punti (P-R): {total_points}\")\n",
    "plt.xlabel('Periodo Orbitale (giorni)')\n",
    "plt.ylabel('Raggio Planetario (R_J)')\n",
    "plt.legend(bbox_to_anchor=(1.03, 1), loc='upper left')\n",
    "ax = plt.gca()\n",
    "y_ticks = ax.get_yticks()\n",
    "plt.yticks(y_ticks, [f\"{tick:.2e}\" for tick in y_ticks])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "PR_name = get_unique_filename('P-R', '.png', 'Clusters/')\n",
    "plt.suptitle('Rapporto Periodo-Raggio (1° livello)')\n",
    "plt.savefig(PR_name, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "total_points = 0\n",
    "# Plot Rapporto Periodo-Massa (1° livello)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, cl in enumerate(categories_lvl1):\n",
    "    mask = df_clustered['cluster_livello1'] == cl\n",
    "    if mask.sum() > 0:\n",
    "        plt.scatter(\n",
    "            df_clustered.loc[mask, 'planet_orbital_period'],\n",
    "            df_clustered.loc[mask, 'planet_mass_kg'],\n",
    "            color=colors_lvl1[i],\n",
    "            alpha=0.7,\n",
    "            edgecolors='black',\n",
    "            label=f'C1: {cl}'\n",
    "        )\n",
    "    total_points += mask.sum()\n",
    "print(f\"Totale punti (P-M): {total_points}\")\n",
    "\n",
    "plt.xlabel('Periodo Orbitale (giorni)')\n",
    "plt.ylabel('Massa Planetaria (kg)')\n",
    "plt.legend(bbox_to_anchor=(1.03, 1), loc='upper left')\n",
    "ax = plt.gca()\n",
    "y_ticks = ax.get_yticks()\n",
    "plt.yticks(y_ticks, [f\"{tick:.2e}\" for tick in y_ticks])\n",
    "plt.xticks(ax.get_xticks())\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "PM_name = get_unique_filename('P-M', '.png', 'Clusters/')\n",
    "plt.suptitle('Rapporto Periodo-Massa (1° livello)')\n",
    "plt.savefig(PM_name, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- Grafici basati sulle categorie fisiche con miglioramento della visibilità ---\n",
    "\n",
    "# Plot Rapporto Periodo-Raggio (Categorie fisiche)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# JITTERED\n",
    "'''\n",
    "for cat, color in phys_color_map.items():\n",
    "    mask = df_clustered['phys_category'] == cat\n",
    "    # Applica jitter alle coordinate per ridurre l'overplotting\n",
    "    x = df_clustered.loc[mask, 'planet_orbital_period'] + np.random.normal(0, jitter_x, size=mask.sum())\n",
    "    y = df_clustered.loc[mask, 'planet_radius'] + np.random.normal(0, jitter_radius, size=mask.sum())\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        color=color,\n",
    "        s=marker_size,\n",
    "        alpha=alpha_val,\n",
    "        edgecolors='black',\n",
    "        label=cat\n",
    "    )\n",
    "'''\n",
    "total_points = 0\n",
    "# UNJITTERED\n",
    "for cat, color in phys_color_map.items():\n",
    "    mask = df_clustered['phys_category'] == cat\n",
    "    # Rimuovi completamente il jitter\n",
    "    x = df_clustered.loc[mask, 'planet_orbital_period']\n",
    "    y = df_clustered.loc[mask, 'planet_radius']\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        color=color,\n",
    "        s=7,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        label=cat\n",
    "    )\n",
    "    total_points += mask.sum()\n",
    "print(f\"Totale punti (P-R_phys): {total_points}\")\n",
    "plt.xlabel('Periodo Orbitale (giorni)')\n",
    "plt.ylabel('Raggio Planetario (R_J)')\n",
    "plt.legend(bbox_to_anchor=(1.03, 1), loc='upper left')\n",
    "plt.suptitle('Rapporto Periodo-Raggio (Categorie Fisiche)')\n",
    "ax = plt.gca()\n",
    "y_ticks = ax.get_yticks()\n",
    "plt.yticks(y_ticks, [f\"{tick:.2e}\" for tick in y_ticks])\n",
    "plt.xticks(ax.get_xticks())\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "PR_phys_name = get_unique_filename('P-R_phys_log', '.png', 'Clusters/')\n",
    "plt.savefig(PR_phys_name, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "total_points = 0\n",
    "# Plot Rapporto Periodo-Massa (Categorie fisiche)\n",
    "plt.figure(figsize=(10, 6))\n",
    "'''\n",
    "for cat, color in phys_color_map.items():\n",
    "    mask = df_clustered['phys_category'] == cat\n",
    "    # Applica jitter alle coordinate per ridurre l'overplotting\n",
    "    x = df_clustered.loc[mask, 'planet_orbital_period'] + np.random.normal(0, jitter_x, size=mask.sum())\n",
    "    y = df_clustered.loc[mask, 'planet_mass_kg'] + np.random.normal(0, jitter_mass, size=mask.sum())\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        color=color,\n",
    "        s=marker_size,\n",
    "        alpha=alpha_val,\n",
    "        edgecolors='black',\n",
    "        label=cat\n",
    "    )\n",
    "'''\n",
    "for cat, color in phys_color_map.items():\n",
    "    mask = df_clustered['phys_category'] == cat\n",
    "    # Rimuovi completamente il jitter\n",
    "    x = df_clustered.loc[mask, 'planet_orbital_period']\n",
    "    y = df_clustered.loc[mask, 'planet_mass_kg']\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        color=color,\n",
    "        s=7,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        label=cat\n",
    "    )\n",
    "    total_points += mask.sum()\n",
    "print(f\"Totale punti (P-M_phys): {total_points}\")\n",
    "plt.xlabel('Periodo Orbitale (giorni)')\n",
    "plt.ylabel('Massa Planetaria (kg)')\n",
    "plt.legend(bbox_to_anchor=(1.03, 1), loc='upper left')\n",
    "plt.suptitle('Rapporto Periodo-Massa (Categorie Fisiche)')\n",
    "ax = plt.gca()\n",
    "y_ticks = ax.get_yticks()\n",
    "plt.yticks(y_ticks, [f\"{tick:.2e}\" for tick in y_ticks])\n",
    "plt.xticks(ax.get_xticks())\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "PM_phys_name = get_unique_filename('P-M_phys_log', '.png', 'Clusters/')\n",
    "plt.savefig(PM_phys_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvataggio risultati\n",
    "### Salviamo i risultati mediante `to_competition_format()`, nel formato richiesto dalla Challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = to_competition_format(tracedata_arr=all_p, weights_arr=all_w)\n",
    "#out_name = get_unique_filename('Submission','.hdf5','./output/')\n",
    "#out_RT = to_regular_track_format(tracedata_arr=all_p, weights_arr=all_w,name=out_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
