{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doppio clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import sys\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import taurex.log\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import mixture\n",
    "from bayesian_bootstrap import bayesian_bootstrap\n",
    "from helper import *\n",
    "from helper import *\n",
    "from preprocessing import *\n",
    "from submit_format import to_competition_format\n",
    "from posterior_utils import *\n",
    "from spectral_metric import *\n",
    "from FM_utils_final import *\n",
    "\n",
    "taurex.log.disableLogging()\n",
    "np.set_printoptions(suppress=True,linewidth=np.nan,threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 5\n",
    "random_state = 420\n",
    "\n",
    "# Lettura dati dai file \n",
    "aux = np.load('aux.npy')\n",
    "spec_matrix = np.load('spectra.npy')\n",
    "noise = np.load('noise.npy')\n",
    "labels = np.load('label.npy')\n",
    "validTraces = np.load('validTraces.npy')\n",
    "\n",
    "# Setting dei path\n",
    "\n",
    "## PARTIAL DATASET\n",
    "# training_path = './Training/'\n",
    "\n",
    "## FUL DATASET\n",
    "training_path = './Full_Dataset/Level2Data/'\n",
    "training_GT_path = os.path.join(training_path, 'Ground Truth Package')\n",
    "trace_GT = h5py.File(os.path.join(training_GT_path, 'TraceData.hdf5'),\"r\")\n",
    "\n",
    "validTraces = validTraces.astype(int)\n",
    "num_spectra = spec_matrix.shape[0]\n",
    "\n",
    "vt = validTraces\n",
    "test_ind = np.sort(vt-1) #vt[:split]-1\n",
    "train_ind = np.setdiff1d(np.arange(num_spectra),test_ind)\n",
    "plot_ind = random.sample(range(len(test_ind)), 10)\n",
    "spectra_ind = random.sample(range(len(test_ind)), 10)\n",
    "\n",
    "test_spectra = spec_matrix[test_ind,:]\n",
    "test_spectra = augment_data(test_spectra, noise[test_ind,:], repeat=1)\n",
    "test_spectra = test_spectra.reshape(-1, spec_matrix.shape[1])\n",
    "#test_spectra = normalize(test_spectra, axis=0, norm='max')\n",
    "\n",
    "train_spectra = spec_matrix[train_ind,:]\n",
    "train_spectra = augment_data(train_spectra, noise[train_ind,:], repeat=n_repeat)\n",
    "train_spectra = train_spectra.reshape(-1, spec_matrix.shape[1])\n",
    "#train_spectra = normalize(train_spectra, axis=0, norm='max')\n",
    "\n",
    "train_aux = aux[train_ind,:]\n",
    "train_aux = np.repeat(train_aux, repeats=n_repeat, axis=0)\n",
    "test_aux = aux[test_ind,:]\n",
    "\n",
    "train_labels = labels[train_ind,:]\n",
    "train_labels = np.repeat(train_labels, repeats=n_repeat, axis=0)\n",
    "test_labels = labels[test_ind,:]\n",
    "\n",
    "# Setting dei parametri cercati\n",
    "labels_names = ['planet_radius','planet_temp', 'log_H2O', 'log_CO2', 'log_CO', 'log_CH4', 'log_NH3']\n",
    "# Controllo della compatibilita' dei size con l'input richiesto dal modello\n",
    "RJUP = 69911000\n",
    "MJUP = 1.898e27\n",
    "RSOL = 696340000\n",
    "Rs = aux[:,2]/RSOL #['star_radius_m']\n",
    "# Rp = aux_df['planet_radius_m']/RJUP\n",
    "Mp = aux[:,4]/MJUP #['planet_mass_kg']\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametri di clustering\n",
    "- K1 : numero di cluster di 1o livello\n",
    "- K2 : numero di 'sottocluster' (cluster di 2o livello)\n",
    "- GMM_i : output del Gaussian Mixture Model\n",
    "- Labels_i : labels ottenute dal GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 10\n",
    "K2 = 20\n",
    "GMM_i = []\n",
    "Labels_i = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applicazione del Clustering\n",
    "> Cerchiamo, in ogni sottocluster (K2), i cluster contenenti un singolo spettro, che sono considerati *outlier*, cioe' anomali (composti da un solo spettro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = mixture.GaussianMixture(n_components=K1, random_state=random_state, max_iter=500).fit(train_aux)\n",
    "labels_1 = gmm.predict(train_aux)\n",
    "for i in range(K1):\n",
    "    spectra_i = np.where(labels_1 == i)[0]  # Indici degli spettri che appartengono al cluster i\n",
    "    print(\"Clustering spettro #\", i, \" -> \", len(spectra_i))\n",
    "    \n",
    "    # Secondo clustering (2° livello) sul sottoinsieme di spettri\n",
    "    tmp = mixture.GaussianMixture(n_components=K2, random_state=random_state, max_iter=500).fit(train_spectra[spectra_i, :])\n",
    "    labels_2 = tmp.predict(train_spectra[spectra_i, :])\n",
    "    GMM_i.append(tmp)\n",
    "    Labels_i.append(labels_2)\n",
    "    \n",
    "    for j in range(K2):\n",
    "        spectra_j = np.where(labels_2 == j)[0]\n",
    "        if len(spectra_j) == 1:\n",
    "            # Se il j-simo sottocluster dell'i-simo cluster contiene un solo spettro, lo consideriamo outlier\n",
    "            print(f\"\\tSpettri nel cluster # {i} : {j}, -> len:{len(spectra_j)} [OUTLIER]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup per gli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_scores = []\n",
    "spectral_scores = []\n",
    "bounds_matrix = default_prior_bounds()\n",
    "beta = 0.8\n",
    "q_list = np.linspace(0.01, 0.99, 10)\n",
    "## Path variables\n",
    "opacity_path = \"./XSEC/\"\n",
    "CIA_path = \"./HITRAN\"\n",
    "## read in spectral grid\n",
    "ariel_wlgrid, ariel_wlwidth, ariel_ngrid, ariel_wnwidth = ariel_resolution()\n",
    "## Initialise base T3 model for ADC2023\n",
    "fm = initialise_forward_model(opacity_path, CIA_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo degli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in range(len(test_ind)):\n",
    "    min_w = 1e-8\n",
    "    idx1 = gmm.predict(test_aux[X, :].reshape(1, -1))[0]\n",
    "    km = GMM_i[idx1]\n",
    "    labels_2 = Labels_i[idx1]\n",
    "    idx2 = km.predict(test_spectra[X, :].reshape(1, -1))[0]\n",
    "    idx_1 = np.where(labels_1 == idx1)[0]\n",
    "    idx_2 = np.where(labels_2 == idx2)[0]\n",
    "    lab = train_labels[idx_1[idx_2], :6]\n",
    "    posterior = lab\n",
    "    weights1 = np.ones((posterior.shape[0], 1)) / np.sum(np.ones(posterior.shape[0]))\n",
    "\n",
    "    try:\n",
    "        tr_GT = trace_GT[f'Planet_{test_ind[X]+1}']['tracedata'][()]\n",
    "    except KeyError:\n",
    "        print(f\"Skipping test sample {X} due to KeyError when accessing trace data.\")\n",
    "        continue\n",
    "\n",
    "    # Se tr_GT è una tuple, estraiamo il primo elemento\n",
    "    if isinstance(tr_GT, tuple):\n",
    "        if not tr_GT:\n",
    "            print(f\"Skipping test sample {X} because tr_GT is an empty tuple.\")\n",
    "            continue\n",
    "        tr_GT = tr_GT[0]\n",
    "\n",
    "    # Verifica che tr_GT sia un array valido\n",
    "    if not isinstance(tr_GT, np.ndarray):\n",
    "        print(f\"Skipping test sample {X} because tr_GT is not a valid array.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        wh_GT = trace_GT[f'Planet_{test_ind[X]+1}']['weights'][()]\n",
    "    except KeyError:\n",
    "        print(f\"Skipping test sample {X} due to KeyError when accessing weight data.\")\n",
    "        continue\n",
    "    except Exception:\n",
    "        print(f\"Skipping test sample {X} due to an unexpected error when accessing weight data.\")\n",
    "        continue\n",
    "\n",
    "    if posterior.shape[0] < 2:\n",
    "        print(f\"Skipping test sample {X} because of too few traces. Dimension is {posterior.shape[0]}\")\n",
    "        continue\n",
    "\n",
    "    if np.isnan(tr_GT).sum() > 0 or np.isinf(tr_GT).sum() > 0:\n",
    "        continue\n",
    "    if np.isnan(weights1).sum() > 0 or np.isinf(weights1).sum() > 0:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        score = compute_posterior_loss(posterior, weights1, tr_GT, wh_GT, bounds_matrix)\n",
    "    except (IndexError, FloatingPointError) as e:\n",
    "        continue\n",
    "    else:\n",
    "        if not np.isnan(score):\n",
    "            posterior_scores.append(score)\n",
    "\n",
    "    if X in spectra_ind:\n",
    "        proxy_compute_spectrum = setup_dedicated_fm(fm, X, Rs, Mp, ariel_ngrid, ariel_wnwidth)\n",
    "        score = compute_spectral_loss(posterior, weights1, tr_GT, wh_GT, bounds_matrix, proxy_compute_spectrum, q_list)\n",
    "        spectral_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcolo degli score medi\n",
    "- Posterior Score : 80%\n",
    "- Spectral Score : 20%\n",
    "- Final score = Score finale per la Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_posterior_score = np.mean(posterior_scores) \n",
    "print(f'Posterior_Score: {avg_posterior_score}')\n",
    "\n",
    "avg_spectral_score = np.mean(spectral_scores)\n",
    "print(f'Spectral_Score: {avg_spectral_score}')\n",
    "\n",
    "final_score = (1-beta)*avg_spectral_score + beta *avg_posterior_score\n",
    "print(f\"final loss is {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting delle distribuzioni\n",
    "### Si utiliza 'corner' per il plot delle distribuzioni bayesiane a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in plot_ind:\n",
    "    idx1 = gmm.predict(test_aux[X, :].reshape(1, -1))[0]\n",
    "    km = GMM_i[idx1]\n",
    "    labels_2 = Labels_i[idx1]\n",
    "    idx2 = km.predict(test_spectra[X, :].reshape(1, -1))[0]\n",
    "    score = km.score_samples(test_spectra[X, :].reshape(1, -1))[0]\n",
    "    idx_1 = np.where(labels_1 == idx1)[0]\n",
    "    idx_2 = np.where(labels_2 == idx2)[0]\n",
    "   \n",
    "    \n",
    "    try:\n",
    "        tr_GT = trace_GT[f'Planet_{test_ind[X]+1}']['tracedata'][()]\n",
    "    except KeyError:\n",
    "        print(f\"Skipping plot {X} due to KeyError when accessing trace data.\")\n",
    "        continue\n",
    "        \n",
    "    if isinstance(tr_GT, tuple):\n",
    "        if not tr_GT:\n",
    "            print(f\"Skipping plot {X} because tr_GT is an empty tuple.\")\n",
    "            continue\n",
    "        try:\n",
    "            tr_GT = tr_GT[0]\n",
    "        except IndexError:\n",
    "           print(f\"Skipping plot {X} because tr_GT is a non-empty tuple but unpacking failed.\")\n",
    "           continue\n",
    "    \n",
    "    try:\n",
    "        tr_GT = np.asarray(tr_GT, dtype=np.float64)\n",
    "    except:\n",
    "        print(f\"Skipping plot {X} because tr_GT cannot be converted to a NumPy array.\")\n",
    "        continue\n",
    "    \n",
    "    if not isinstance(tr_GT, np.ndarray):\n",
    "        print(f\"Skipping plot {X} because tr_GT is not a valid array.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        wh_GT = trace_GT[f'Planet_{test_ind[X]+1}']['weights'][()]\n",
    "    except KeyError:\n",
    "        print(f\"Skipping plot {X} due to KeyError when accessing weight data.\")\n",
    "        continue\n",
    "    \n",
    "    if tr_GT is None:\n",
    "        print(f\"Skipping plot {X} because tr_GT is None.\")\n",
    "        continue\n",
    "\n",
    "    if not hasattr(tr_GT, 'shape') or len(tr_GT.shape) < 1 :\n",
    "         print(f\"Skipping plot {X} because tr_GT has invalid shape: {tr_GT}.\")\n",
    "         continue\n",
    "    if  len(tr_GT.shape) !=2 :\n",
    "         print(f\"Skipping plot {X} because tr_GT does not have shape with length 2: {tr_GT.shape}\")\n",
    "         continue\n",
    "    if np.isnan(tr_GT).any():\n",
    "         print(f\"Skipping plot {X} because tr_GT has nan values: {tr_GT}\")\n",
    "         continue\n",
    "        \n",
    "    if tr_GT.shape[0] > 1:\n",
    "       Tp = tr_GT[1]\n",
    "    else:\n",
    "       Tp = tr_GT[0]\n",
    "\n",
    "    lab = train_labels[idx_1[idx_2], :]\n",
    "    \n",
    "    if lab.shape[0] != tr_GT.shape[0]:\n",
    "        if lab.shape[0] > tr_GT.shape[0]:\n",
    "            lab_indices = np.random.choice(lab.shape[0], tr_GT.shape[0], replace=False)\n",
    "            lab = lab[lab_indices]\n",
    "        else: \n",
    "            lab_indices = np.random.choice(lab.shape[0], tr_GT.shape[0], replace=True)\n",
    "            lab = lab[lab_indices]\n",
    "\n",
    "    mean_lab = np.mean(lab, axis=0)\n",
    "\n",
    "    # Calcola il punteggio e aggiungi ai risultati\n",
    "    score = compute_posterior_loss(posterior, weights1, tr_GT, wh_GT, bounds_matrix)\n",
    "    posterior_scores.append(score)\n",
    "    if X in spectra_ind:\n",
    "        proxy_compute_spectrum = setup_dedicated_fm(fm, X, Rs, Mp, ariel_ngrid, ariel_wnwidth)\n",
    "        score = compute_spectral_loss(posterior, weights1, tr_GT, wh_GT, bounds_matrix, proxy_compute_spectrum, q_list)\n",
    "        spectral_scores.append(score)\n",
    "    # Generazione dei corner plot\n",
    "    concatenated_data = np.concatenate((tr_GT, lab), axis=1)\n",
    "    \n",
    "    \n",
    "    K = concatenated_data.shape[1]\n",
    "    \n",
    "    figure = corner.corner(concatenated_data, quiet=True)\n",
    "    axes = np.array(figure.axes).reshape((K, K))\n",
    "    for i in range(K):\n",
    "        ax = axes[i, i]\n",
    "        ax.sharex(axes[K-1,i])\n",
    "        if i < tr_GT.shape[1]:\n",
    "            ax.axvline(test_labels[X, i], color=\"black\")\n",
    "            ax.axvline(mean_lab[i], color='red')\n",
    "        elif i < K:\n",
    "            ax.axvline(mean_lab[i - tr_GT.shape[1]], color='red')\n",
    "\n",
    "        ax.relim()\n",
    "        ax.autoscale()\n",
    "        ax.set_title(labels_names[i] if i < tr_GT.shape[1] else labels_names[i-tr_GT.shape[1]])\n",
    "    figure.savefig(f'./GMM_plots/corner_plot_{X}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
