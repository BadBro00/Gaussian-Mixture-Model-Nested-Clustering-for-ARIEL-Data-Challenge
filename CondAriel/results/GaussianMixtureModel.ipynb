{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doppio clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import sys\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import taurex.log\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import posterior_utils\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Importa dinamicamente il modulo helper\n",
    "import helper\n",
    "importlib.reload(helper) \n",
    "check_parameters_valid = helper.check_parameters_valid\n",
    "\n",
    "# Aggiungi il percorso della directory contenente helper.py\n",
    "sys.path.append(os.path.abspath('./'))\n",
    "\n",
    "importlib.reload(posterior_utils)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import mixture\n",
    "from helper import *\n",
    "from preprocessing import *\n",
    "from submit_format import to_competition_format\n",
    "from posterior_utils import *\n",
    "from spectral_metric import *\n",
    "from FM_utils_final import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.lines import Line2D\n",
    "from submit_format import get_unique_filename\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# plt.style.use('default')\n",
    "#plt.rcParams['axes.prop_cycle'] = plt.cycler(color=['red'])\n",
    "\n",
    "taurex.log.disableLogging()\n",
    "np.set_printoptions(suppress=True, linewidth=np.nan, threshold=sys.maxsize)\n",
    "\n",
    "# Filtering dei Warning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"more than 1 Rp value detected in the trace! Using first value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 5\n",
    "random_state = 420\n",
    "# random_state = random.randint(1,1000)\n",
    "# print(f'Random State : {random_state}')\n",
    "\n",
    "# Lettura dati dai file \n",
    "aux = np.load('aux.npy')\n",
    "spec_matrix = np.load('spectra.npy')\n",
    "noise = np.load('noise.npy')\n",
    "labels = np.load('label.npy')\n",
    "validTraces = np.load('validTraces.npy')\n",
    "num_spectra = spec_matrix.shape[0]\n",
    "labels_names = ['planet_radius','planet_temp','log_H2O','log_CO2','log_CO','log_CH4','log_NH3']\n",
    "\n",
    "# Setting dei path\n",
    "training_path = './Check_Dataset/TrainingData'\n",
    "training_GT_path = os.path.join(training_path, 'Ground Truth Package')\n",
    "trace_GT = h5py.File(os.path.join(training_GT_path, 'TraceData.hdf5'), \"r\")\n",
    "validTraces = validTraces.astype(np.int64)\n",
    "\n",
    "for X in trace_GT.keys():\n",
    "    tr_GT = trace_GT[X]['tracedata'][()]\n",
    "    weights_GT = trace_GT[X]['weights'][()]\n",
    "    if np.isnan(tr_GT).sum() == 1:\n",
    "        continue\n",
    "    validTraces = np.append(validTraces, int(X[12:]))\n",
    "\n",
    "vt = validTraces\n",
    "test_ind = np.sort(vt - 1)\n",
    "train_ind = np.setdiff1d(np.arange(num_spectra), test_ind)\n",
    "plot_ind = random.sample(range(len(test_ind)), 10)\n",
    "spectra_ind = random.sample(range(len(test_ind)), 10)\n",
    "\n",
    "# Preprocessing dei dati spettrali\n",
    "\n",
    "# Preprocessamento dei test spectra\n",
    "test_spectra = spec_matrix[test_ind, :]\n",
    "test_spectra = augment_data(test_spectra, noise[test_ind, :], repeat=1)\n",
    "test_spectra = test_spectra.reshape(-1, spec_matrix.shape[1])\n",
    "\n",
    "# Preprocessamento dei train spectra\n",
    "train_spectra = spec_matrix[train_ind, :]\n",
    "train_spectra = augment_data(train_spectra, noise[train_ind, :], repeat=n_repeat)\n",
    "train_spectra = train_spectra.reshape(-1, spec_matrix.shape[1])\n",
    "\n",
    "# Applichiamo StandardScaler per preservare meglio la distribuzione originale\n",
    "scaler = StandardScaler()\n",
    "train_spectra = scaler.fit_transform(train_spectra)\n",
    "test_spectra = scaler.transform(test_spectra)\n",
    "\n",
    "# Dati ausiliari e labels\n",
    "train_aux = aux[train_ind, :]\n",
    "train_aux = np.repeat(train_aux, repeats=n_repeat, axis=0)\n",
    "test_aux = aux[test_ind, :]\n",
    "train_labels = labels[train_ind, :]\n",
    "train_labels = np.repeat(train_labels, repeats=n_repeat, axis=0)\n",
    "test_labels = labels[test_ind, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applicazione del Clustering\n",
    "- $K_1$ : numero di cluster di 1o livello\n",
    "- $K_2$ : numero di 'sottocluster' (cluster di 2o livello)\n",
    "- $GMM_i$ : output del Gaussian Mixture Model\n",
    "- $Labels_i$ : labels ottenute dal GMM\n",
    "> Cerchiamo, in ogni sottocluster (K2), i cluster contenenti un singolo spettro, che sono considerati *outlier*, cioe' anomali (composti da un solo spettro)\n",
    "### Si puo' usare il BIC (o l'AIC) per ottenere **i valori ottimali** di $K_1$ e $K_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (19,10) sembra essere la migliore coppia per il clustering [Risultato BIC]\n",
    "K1 = 19\n",
    "K2 = 5\n",
    "GMM_i = []\n",
    "Labels_i = []\n",
    "gmm = mixture.GaussianMixture(n_components=K1, random_state=random_state, max_iter=400).fit(train_aux)\n",
    "labels_1 = gmm.predict(train_aux)\n",
    "for i in range(K1):\n",
    "    spectra_i = np.where(labels_1 == i)[0]\n",
    "    print(\"Spettri nel cluster #\", i, \" -> \", len(spectra_i))\n",
    "    # Secondo clustering (2Â° livello) sui dati spettrali appartenenti al cluster i\n",
    "    tmp = mixture.GaussianMixture(n_components=K2, random_state=random_state).fit(train_spectra[spectra_i, :])\n",
    "    labels_2 = tmp.predict(train_spectra[spectra_i, :])\n",
    "    GMM_i.append(tmp)\n",
    "    Labels_i.append(labels_2)\n",
    "    for j in range(K2):\n",
    "        spectra_j = np.where(labels_2 == j)[0]\n",
    "        if len(spectra_j) == 1:\n",
    "            print(f\"\\t [{i}].{j} sottocluster con singolo spettro [OUTLIER]\")\n",
    "            #spectra_i = np.delete(spectra_i,spectra_j) # Rimozione dell'outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup per gli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_scores = []\n",
    "spectral_scores = []\n",
    "bounds_matrix = default_prior_bounds()\n",
    "beta = 0.8\n",
    "q_list = np.linspace(0.01, 0.99, 10)\n",
    "opacity_path = \"./XSEC/\"\n",
    "CIA_path = \"./HITRAN\"\n",
    "ariel_wlgrid, ariel_wlwidth, ariel_wngrid, ariel_wnwidth = ariel_resolution()\n",
    "fm = initialise_forward_model(opacity_path, CIA_path)\n",
    "RJUP = 69911000\n",
    "MJUP = 1.898e27\n",
    "RSOL = 696340000\n",
    "Rs = aux[:, 2] / RSOL\n",
    "Mp = aux[:, 4] / MJUP\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo degli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_max = 20\n",
    "n_spec = 0\n",
    "spec_ind = random.sample(range(len(test_ind)),spec_max*2)\n",
    "k1_vals = []\n",
    "k2_vals = []\n",
    "spec_maxes = []\n",
    "clustering_vals = []\n",
    "subclustering_vals = []\n",
    "posterior_scores_k = []\n",
    "spectral_scores_k = []\n",
    "scores_k = []\n",
    "spec_maxes = []\n",
    "spec_inds = []\n",
    "\n",
    "for X in range(len(test_ind)):\n",
    "\tidx1 = gmm.predict(test_aux[X, :].reshape(1, -1))[0]\n",
    "\tkm = GMM_i[idx1]\n",
    "\tlabels_2 = Labels_i[idx1]\n",
    "\tidx2 = km.predict(test_spectra[X, :].reshape(1, -1))[0]\n",
    "\tidx_1 = np.where(labels_1 == idx1)[0]\n",
    "\tidx_2 = np.where(labels_2 == idx2)[0]\n",
    "\tcluster_membs = idx_1[labels_2==idx2]\n",
    "\tlab = train_labels[cluster_membs,:]\n",
    "\tlab = lab.reshape(-1,lab.shape[-1])\n",
    "\tposterior = lab\n",
    "\tweights1 = np.ones((posterior.shape[0],1)) / posterior.shape[0]\n",
    "\tplanet_index = test_ind[X]+1\n",
    "\ttr_GT = trace_GT[f'Planet_train{planet_index}']['tracedata'][()] # Corrected Planet ID format\n",
    "\twh_GT = trace_GT[f'Planet_train{planet_index}']['weights'][()] # Corrected Planet ID format\n",
    "\tif np.isnan(tr_GT).sum() >= 1:\n",
    "\t\tprint(\"nan trovato\")\n",
    "\t\texit()\n",
    "\tscore = compute_posterior_loss(posterior, weights1, tr_GT, wh_GT,bounds_matrix)\n",
    "\tposterior_scores.append(score)\n",
    "\tif n_spec<spec_max and X in spec_ind:\n",
    "\t\ttry:\n",
    "\t\t\tproxy_compute_spectrum = setup_dedicated_fm(fm, test_ind[X], Rs, Mp, ariel_wngrid, ariel_wnwidth )\n",
    "\t\t\tsscore = compute_spectral_loss(posterior, weights1, tr_GT, wh_GT, bounds_matrix, proxy_compute_spectrum, q_list)\n",
    "\t\t\tspectral_scores.append(sscore)\n",
    "\t\t\tprint('*****Spectral: ',sscore)\n",
    "\t\t\tprint('*****Posterior: ',score)\n",
    "\t\t\tspec_inds.append(X)\n",
    "\t\t\tn_spec+=1\n",
    "\t\texcept RuntimeWarning:\n",
    "\t\t\tcontinue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcolo degli score medi\n",
    "- Posterior Score : 80%\n",
    "- Spectral Score : 20%\n",
    "- Final score = Score finale per la Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_posterior_score = np.mean(posterior_scores)\n",
    "print(f'Posterior_Score: {avg_posterior_score}')\n",
    "avg_spectral_score = np.mean(spectral_scores)\n",
    "print(f'Spectral_Score: {avg_spectral_score}')\n",
    "final_score = (1 - beta) * avg_spectral_score + beta * avg_posterior_score\n",
    "print(f\"final score: {final_score:.4f}\")\n",
    "\n",
    "k1_vals.append(K1)\n",
    "k2_vals.append(K2)\n",
    "# clustering_vals.append((K1,K2))\n",
    "clustering_vals.append(K1)\n",
    "subclustering_vals.append(K2)\n",
    "cluster_ids = list(range(len(clustering_vals)))\n",
    "posterior_scores_k.append(avg_posterior_score)\n",
    "spectral_scores_k.append(avg_spectral_score)\n",
    "spec_maxes.append(spec_max)\n",
    "scores_k.append(final_score)\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "    f.write(\"\\n------------------------------\\n\")\n",
    "    f.write(\"K1: {}\\n\".format(k1_vals))\n",
    "    f.write(\"K2: {}\\n\".format(k2_vals))\n",
    "    f.write(\"Posterior scores: {}\\n\".format(posterior_scores_k))\n",
    "    f.write(\"Spectral scores: {}\\n\".format(spectral_scores_k))\n",
    "    f.write(\"Final scores: {}\\n\".format(scores_k))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting grafico Score/Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_plot_ind = 0\n",
    "# Leggi l'intero contenuto del file\n",
    "with open(\"results.txt\", \"r\") as f:\n",
    "    content = f.read() \n",
    "\n",
    "# Suddividi in blocchi\n",
    "blocks = [block for block in content.split('------------------------------') if block.strip()]\n",
    "\n",
    "# Inizializza le liste\n",
    "k_pairs = []  # Salva le coppie (K1,K2)\n",
    "posterior_list = []\n",
    "spectral_list = []\n",
    "final_list = []\n",
    "\n",
    "def safe_literal_eval(value):\n",
    "    try:\n",
    "        value = value.strip().lower()\n",
    "        if value == \"nan\":\n",
    "            return np.nan\n",
    "        return ast.literal_eval(value)\n",
    "    except (SyntaxError, ValueError):\n",
    "        print(f\"Errore nel parsing: {value}\")\n",
    "        return None\n",
    "\n",
    "for block in blocks:\n",
    "    k1, k2 = None, None\n",
    "    posterior = spectral = final = None\n",
    "    \n",
    "    lines = [line.strip() for line in block.strip().splitlines() if line.strip()]\n",
    "    for line in lines:\n",
    "        if line.startswith(\"K1:\"):\n",
    "            k1 = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"K2:\"):\n",
    "            k2 = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Posterior\"):\n",
    "            posterior = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Spectral\"):\n",
    "            spectral = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Final\"):\n",
    "            final = safe_literal_eval(line.split(\":\", 1)[1].strip())\n",
    "    \n",
    "    if all(v is not None for v in [k1, k2, posterior, spectral, final]):\n",
    "        k_pairs.append(f\"({k1},{k2})\")\n",
    "        posterior_list.append(np.mean(posterior) if isinstance(posterior, (list, tuple, np.ndarray)) else posterior)\n",
    "        spectral_list.append(np.mean(spectral) if isinstance(spectral, (list, tuple, np.ndarray)) else spectral)\n",
    "        final_list.append(np.mean(final) if isinstance(final, (list, tuple, np.ndarray)) else final)\n",
    "\n",
    "# Crea il plot con coppie K1,K2\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_pos = np.arange(len(k_pairs))  # Posizioni per le barre/ticks\n",
    "\n",
    "# Line plot per i tre score\n",
    "plt.plot(x_pos, posterior_list, marker='o', color='red', label='Posterior Score', linestyle='--')\n",
    "plt.plot(x_pos, spectral_list, marker='s', color='black', label='Spectral Score', linestyle='-.')\n",
    "plt.plot(x_pos, final_list, marker='D', color='blue', label='Final Score', linestyle=':')\n",
    "\n",
    "# Formattazione assi\n",
    "plt.xticks(x_pos, k_pairs, rotation=45, ha='right', fontsize=8)\n",
    "plt.xlabel('(K1, K2)', fontweight='bold')\n",
    "plt.ylabel('Scores', fontweight='bold')\n",
    "plt.title('Confronto Scores per Configurazioni (K1,K2)', pad=20)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Aggiungi valori sugli ultimi punti\n",
    "for i, (p, s, f) in enumerate(zip(posterior_list, spectral_list, final_list)):\n",
    "    plt.annotate(f'{p:.1f}', (x_pos[i], p), textcoords=\"offset points\", xytext=(0,5), ha='center', color='red', fontsize=8)\n",
    "    plt.annotate(f'{s:.1f}', (x_pos[i], s), textcoords=\"offset points\", xytext=(0,5), ha='center', color='black', fontsize=8)\n",
    "    plt.annotate(f'{f:.1f}', (x_pos[i], f), textcoords=\"offset points\", xytext=(0,5), ha='center', color='blue', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_fname = get_unique_filename('Grafico','.png','./Cluster_Scores/')\n",
    "plt.savefig(plot_fname)\n",
    "plt.show()\n",
    "csv_fname = 'results.csv'\n",
    "df_results = pd.DataFrame({\n",
    "    'K1' : [K1],\n",
    "    'K2' : [K2],\n",
    "    'FinalScore' : [final_score]\n",
    "})\n",
    "if os.path.exists(csv_fname):\n",
    "    df_results.to_csv(csv_fname,mode='a',header=False,index=False)\n",
    "else:\n",
    "    df_results.to_csv(csv_fname,mode='w',header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafico andamento clustering\n",
    "### Fissato K1, il grafico indica l'andamento del final_score per il variare di K2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "# print(df.head())\n",
    "df.columns = ['K1','K2','final_score']\n",
    "df = df.sort_values(by=['K1','K2'])\n",
    "k1_values = sorted(df['K1'].unique())\n",
    "plt.figure(figsize=(8,6))\n",
    "colormap = plt.cm.get_cmap('tab10', len(k1_values))\n",
    "for i,k1 in enumerate(k1_values):\n",
    "    subset = df[df['K1']==k1]\n",
    "    plt.plot(\n",
    "        subset['K2'],\n",
    "        subset['final_score'],\n",
    "        marker='o',\n",
    "        label=f'K1={k1}',\n",
    "        color=colormap(i)\n",
    "    )\n",
    "plt.xticks(np.arange(1,22,2))\n",
    "plt.xlabel('K2')\n",
    "plt.ylabel('Final Score')\n",
    "plt.title('Andamento score al variare di K2, per K1')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "y_min, y_max = plt.ylim()  # prendi i limiti correnti\n",
    "margine = (y_max - y_min) * 0.1  # 10% di margine\n",
    "plt.ylim(y_min - margine, y_max + margine)\n",
    "fname = get_unique_filename('Grafico','.png',directory='./Grafici_Clustering')\n",
    "plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting delle distribuzioni\n",
    "### Si utiliza 'corner' per il plot delle distribuzioni bayesiane a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for X in plot_ind:\n",
    "\t#dist1 = pairwise_distances(kmeans.cluster_centers_,aux[X,:].reshape(1,-1))\n",
    "\t#idx1 = np.argmin(dist1)\n",
    "\tidx1 = gmm.predict(test_aux[X,:].reshape(1,-1))[0]\n",
    "\n",
    "\tkm = GMM_i[idx1]\n",
    "\tlabels_2 = Labels_i[idx1]\n",
    "\t#dist2 = pairwise_distances(km.cluster_centers_,spec_matrix[X,:].reshape(1,-1))\n",
    "\t#idx2 = np.argmin(dist2)\n",
    "\tidx2 = km.predict(test_spectra[X,:].reshape(1,-1))[0]\n",
    "\t#score = km.score_samples(spec_matrix[X,:].reshape(1,-1))[0]\n",
    "\n",
    "\tidx_1 = np.where(labels_1 == idx1)[0]\n",
    "\tidx_2 = np.where(labels_2 == idx2)[0]\n",
    "\n",
    "\tlab = train_labels[idx_1[idx_2],:]\n",
    "\n",
    "\tmean_lab = np.mean(lab,axis=0)\n",
    "\tmean_GT = np.average(tr_GT,axis=0,weights=wh_GT)\n",
    "\n",
    "\ttr_GT = trace_GT[f'Planet_train{test_ind[X]+1}']['tracedata'][()]\n",
    "\twh_GT = trace_GT[f'Planet_train{test_ind[X]+1}']['weights'][()]\n",
    "\n",
    "\t# TRACES\n",
    "\tfigure = corner.corner(tr_GT,quiet=True) #,weights=wh_GT\n",
    "\t# Extract the axes\n",
    "\taxes = np.array(figure.axes).reshape((tr_GT.shape[1], tr_GT.shape[1]))\n",
    "\t\n",
    "\tlegend_elements = [\n",
    "        Line2D([0], [0], color='blue', lw=2, label='Distribuzione Reale (tr_GT)'),\n",
    "        Line2D([0], [0], color='red', lw=2, label='Distribuzione Predetta (lab)'),\n",
    "        Line2D([0], [0], color='green', lw=2, label='Valore Vero (test_labels)'),\n",
    "        Line2D([0], [0], color='black', lw=2, label='Media Predetta (mean_lab)')\n",
    "    ]\n",
    "    \n",
    "\t# Loop over the diagonal\n",
    "\tfor i in range(tr_GT.shape[1]):\n",
    "\t\tax = axes[i, i]\n",
    "\t\tax.sharex(axes[tr_GT.shape[1]-1,i])\n",
    "\t\tax.axvline(test_labels[X,i], color=\"g\",lw=2)\n",
    "\t\tax.axvline(mean_lab[i], color=\"r\",lw=1.5)\n",
    "\t\tax.axvline(mean_GT[i],color=\"blue\",lw=2)\n",
    "\t    #ax.axvspan(mean_lab[i] - std_lab[i], mean_lab[i] + std_lab[i], alpha=0.3, color='red')\n",
    "\t\tax.relim()\n",
    "\t\tax.autoscale()\n",
    "\t\tax.set_title(labels_names[i])\n",
    "\t\n",
    "\t# Aggiungi la legenda all'angolo in alto a destra\n",
    "\tfigure.legend(\n",
    "        handles=legend_elements, \n",
    "        loc='upper right', \n",
    "        bbox_to_anchor=(0.92, 0.92),\n",
    "        frameon=True,\n",
    "        framealpha=0.9\n",
    "    )\n",
    "\n",
    "\tfigure.set_figheight(8.5)\n",
    "\tfigure.set_figwidth(12)\n",
    "\t# PREDICTED\n",
    "\tcorner.corner(lab,fig=figure,quiet=True, color='red')\n",
    "\t#SAVE\n",
    "\t# figure.savefig(f'./Plots/k1-{K1}_k2-{K2}_{spec_max}spec/Planet_'+str(test_ind[X]+1)+'.png')\n",
    "\tfigure.savefig('./GMM_plots/Planet_'+str(test_ind[X]+1)+'.png')\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
